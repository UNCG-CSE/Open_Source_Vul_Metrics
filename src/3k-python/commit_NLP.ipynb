{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding commit messages\n",
    "### Using NLP Classification and Sentement analysis\n",
    "- The goal is to gain insight to commit messages. More detail is explained in the specific sections below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# nltk.download('stopwords') # Download stopwords\n",
    "plt.rcParams[\"figure.figsize\"] = [13,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining files paths and headers of release and revision csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_header = ['id', 'target', 'date', 'date_offset', 'name', 'comment', 'author']\n",
    "revision_header = ['id', 'date', 'date_offset', 'committer_date', 'committer_date_offset', 'type', 'directory', 'message', 'author', 'committer']\n",
    "# Path to release.csv, and whether to select uncompressed or ocmpressed version\n",
    "revision_path = 'D:/data/open_source/revision.csv.gz'\n",
    "release_path = 'D:/data/open_source/release.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_str(str):\n",
    "    return bytes.fromhex((str).replace('\\\\x','')).decode('utf-8')\n",
    "\n",
    "def msg_str(msg):\n",
    "    return bytes.fromhex(msg[2:]).decode(encoding='ISO-8859-1')\n",
    "\n",
    "def date_str(str):\n",
    "    return pd.to_datetime(str, format='%Y-%m-%dT%H:%M:%S.000Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Commit messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_df = pd.read_csv(release_path, names=release_header, converters={'comment':hex_str})\n",
    "release_df = release_df['comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision Commit messages\n",
    "##### Uses Chunking to import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dateframe\n",
    "revision_df = pd.DataFrame()\n",
    "\n",
    "# Chunk in the data, adding the messages to the df created above\n",
    "chunksize = 10 ** 4\n",
    "for chunk in pd.read_csv(revision_path, chunksize=chunksize, names=revision_header, converters={'message':msg_str}):\n",
    "    revision_df = revision_df.append( chunk['message'].to_frame() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking that the import worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5188989</td>\n",
       "      <td>Fixes for unary and indexing operations.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5188990</td>\n",
       "      <td>Revert \"Update CONTRIBUTING.md\"\\n\\nThis revert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5188991</td>\n",
       "      <td>Improve SEO tools CSS across themes\\n\\nbzr rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5188992</td>\n",
       "      <td>Update CONTRIBUTING.md\\n\\nFixing broken issues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5188993</td>\n",
       "      <td>Only run CoalesceExtSubRegs when we can expect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   message\n",
       "5188989         Fixes for unary and indexing operations.\\n\n",
       "5188990  Revert \"Update CONTRIBUTING.md\"\\n\\nThis revert...\n",
       "5188991  Improve SEO tools CSS across themes\\n\\nbzr rev...\n",
       "5188992  Update CONTRIBUTING.md\\n\\nFixing broken issues...\n",
       "5188993  Only run CoalesceExtSubRegs when we can expect..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "- Difference between release and revision commit messages.\n",
    "- Train NLP Classifier to distinguish between a revision and release commit message.\n",
    "- Sentement analysis between revision and release commit messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to remove special characters from commit messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_commit_msg(msg):\n",
    "    return re.sub('[^A-Za-z0-9 ]+', '', msg)\n",
    "def clean_commit_msgs(msgs):\n",
    "    return msgs.map(clean_commit_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           id                date  \\\n",
      "0  \\xae671a0067dbeabbc3cb546705edc1f81f71a193 2015-02-03 21:58:44   \n",
      "1  \\x33e2c27d1ec224a54ed7ca4a6e09c352e92a227d 2013-07-05 04:58:14   \n",
      "2  \\x1f9bcd823807f41afaab6b74b34473531ca7eb30 2013-03-29 13:02:20   \n",
      "3  \\x3206fb28a040494bac6973310e7f21f031989da6 2010-12-09 04:14:19   \n",
      "4  \\x652fc27cf9fe9262d2c941d6385043efa41016da 2011-11-08 01:22:48   \n",
      "\n",
      "                                     name  \\\n",
      "0  \\x72656c656173652d323031352d30322d3034   \n",
      "1                        \\x76302e32392e31   \n",
      "2                          \\x76332e302e30   \n",
      "3                    \\x6275696c642d343639   \n",
      "4                            \\x312e312e36   \n",
      "\n",
      "                                             comment  author  \n",
      "0                   Release for February 4th, 2015\\n   91949  \n",
      "1                               tag version 0.29.1\\n  140982  \n",
      "2  What's new in Tornado 3.0\\n===================...  207066  \n",
      "3     Windows build SickBeard-win32-alpha-build469\\n  875380  \n",
      "4                                     Fabric 1.1.6\\n   63770  \n",
      "                                             message\n",
      "0  Implement dask.array.take\\n\\nIn principle, we ...\n",
      "1                               Convert to spaces.\\n\n",
      "2  Merge pull request #4887 from cpcloud/groupby-...\n",
      "3  Merge pull request #162 from gabrielhurley/use...\n",
      "4  Update patch set 1\\n\\nPatch Set 1: Presubmit-V...\n"
     ]
    }
   ],
   "source": [
    "print( release_df.head() )\n",
    "print( revision_df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting just the commit messages, and clean them (remove special chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel_msgs = release_df.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (5188994,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bcdbbb01606d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrel_msgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_commit_msgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrel_msgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrevision_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_commit_msgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrevision_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-776f47e4cbd3>\u001b[0m in \u001b[0;36mclean_commit_msgs\u001b[1;34m(msgs)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^A-Za-z0-9 ]+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_commit_msgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmsgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_commit_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   3823\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \"\"\"\n\u001b[1;32m-> 3825\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3826\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (5188994,) and data type float64"
     ]
    }
   ],
   "source": [
    "rel_msgs = clean_commit_msgs(rel_msgs)\n",
    "revision_df = clean_commit_msgs(revision_df['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels are *all* release. This should be changed when revisions are being properly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = rel_msgs.to_frame()\n",
    "rel_df['label'] = 'rel'\n",
    "\n",
    "rel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_df['label'] = 'rev'\n",
    "\n",
    "revision_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_df = revision_df.append(rel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create vectorizer and vectorize the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "msg_vect = vectorizer.fit_transform( msgs['message'] ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the vectorized commit messages into training and testing datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(msg_vect, msg_df['label'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Random Forest Calssifier, train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the trained model, predict using the testing data\n",
    "#### This is not useful for now, since *only* releases are being used. Only 1 label, so no difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n",
    "- \n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit Message Analytics\n",
    "- Most common words used in commit messages.\n",
    "- Average length in a commit message.\n",
    "- ??? ML not used much in this section, so may not be of priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msgs = release_df.iloc[:,3]\n",
    "# msgs = clean_commit_msgs(msgs)\n",
    "\n",
    "msgs = rel_msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the commit messages. Stemmizing and trimming long words.\n",
    "#### Should ensure the cleaning function gets rid of meaningless  numbers / strings. This is a primitive way to to tokenize, so the method used in the 'Classification' section above is likely preferrable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()\n",
    "word_max_length = 20\n",
    "# tokenize, stemmize, and remove stop words\n",
    "msgs_token = []\n",
    "for msg in msgs:\n",
    "    msg = clean_commit_msg(msg)\n",
    "    for w in word_tokenize(msg):\n",
    "        if w not in stop_words and len(w) <= word_max_length:\n",
    "            w_stem = ps.stem(w)\n",
    "            msgs_token.append(w_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msgs_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting to gain some analytics of the data.\n",
    "- Most common words ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df = pd.Series(msgs_token).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df['count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df.columns = ['word', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_counts = msg_df.groupby('word').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_counts['count'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_counts.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
